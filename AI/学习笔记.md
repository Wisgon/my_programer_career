1. numpy 要添加数组，用 np.vstack()，例子：

   ```python
   a = np.array([2,3,4])
   b = np.array([1,2,3])
   c = np.vstack((a,b))
   # c的值是array([[2, 3, 4],[1, 2, 3]])
   ```

   <br><br>

2. 要连接两个 dataframe，用 pd.concat():

   ```python
   newpd = pd.concat([old_df0,  old_df1.iloc[index, :].to_frame().T])
   # 注意，这里的 old_df1.iloc[index, :]得到的是一个Series对象，要用to_frame()转为dataframe，但是，转了之后是倒置的，要将其转置过来
   ```

   <br><br>

3. pandas 中，用 df.replace([np.inf, -np.inf], your_value)来替换 inf 和-inf 值；<br><br>

4. pandas 添加一行数据：`df.loc[df.shape[0]] = {"colum1": xxx, ... }`<br><br>

5. arg min 的意思：arg min 就是使后面这个式子达到最小值时的 x，t 的取值，如：

   ```
   min L(w, b) + R(w)，是指要取损失函数 L(w, b) + R(w)的最小值
   （w`,b`）= argmin L(w, b) + R(w)，是指w`和b`是使损失函数L(w, b) + R(w)最小时的w和b值
   ```

   <br><br>

6. 信息量公式： $I(x_0)=-log(p(x_0))$，图像如下图：
   ![图片](../static/logx.jpg)

   一条信息的信息量大小和它的不确定性有很大的关系。一句话如果需要很多外部信息才能确定，我们就称这句话的信息量比较大。比如你听到“云南西双版纳下雪了”，那你需要去看天气预报、问当地人等等查证（因为云南西双版纳从没下过雪）。相反，如果和你说“人一天要吃三顿饭”，那这条信息的信息量就很小，因为条信息的确定性很高。所以，信息量公式的图像中，$p(x_0)$越大，表示越确定，信息量也就越小，即$I$值越小；<br><br>
   
7. 平均数是实验后根据实际结果统计得到的样本的平均值，期望是实验前根据概率分布“预测”的样本的平均值。之所以说“预测”是因为在实验前能得到的期望与实际实验得到的样本的平均数总会不可避免地存在偏差，毕竟随机实验的结果永远充满着不确定性。如果我们能进行无穷次随机实验并计算出其样本的平均数的话，那么这个平均数其实就是期望。当然实际上根本不可能进行无穷次实验，但是实验样本的平均数会随着实验样本的增多越来越接近期望，就像频率随着实验样本的增多会越来越接近概率一样。**如果说概率是频率随样本趋于无穷的极限，那么期望就是平均数随样本趋于无穷的极限**。<br><br>

8. 如果你想查看这个强化学习算法是model-based还是model-free的，你就问你自己这个问题：**在agent执行它的动作之前，它是否能对下一步的状态和回报做出预测，如果可以，那么就是model-based方法，如果不能，即为model-free方法**。<br><br>

9. 最优贝尔曼方程：$E_{S_{t+1} ∼p(·|s_t ,a_t )} [R_t + γ · max Q (S_{t+1} , A)|S_t = s_t , A_t = a_t ]$，其中的$E_{S_{t+1} ∼p(·|s_t ,a_t )}$的下标表示，$S_{t+1}$是由$p(·|s_t,a_t)$这个分布里抽样出来的；<br><br>

10. 在fully observation，也就是agent能看到所有的环境参数下，observation和state是相等的，而在某些情况下，比如玩扑克牌，observation只有自己的牌和已打出的牌，而state是所有的信息，包括对手的牌和未摸的牌，也就是说，state是所有信息，而observation只是观测到的信息；<br><br>

11. numpy中，True和False的数组可以乘以某个数，True的为1，False的为0，如：

    ```python
    a = np.array([True, False])
    b = a * 3
    print(b)  # [3, 0]
    ```

    <br><br>

12. 

